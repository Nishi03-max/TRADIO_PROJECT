# NIFTY Intraday Price Prediction Project - Status

## âœ… Project Setup Complete

### Data Files
- âœ… **nifty_intraday.csv** in `data/raw/` folder (29.6 MB, 318,982 rows)
- âœ… Contains 10 columns: id, symbol, timestamp, open, high, low, close, volume, open_interest, exchange

### Project Structure
```
NIFTY_MODEL/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/nifty_intraday.csv (ready)
â”‚   â””â”€â”€ processed/ (will be created during execution)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb (ready)
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb (ready)
â”‚   â””â”€â”€ 03_model_experiments.ipynb (ready)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py (ready with column mapping)
â”‚   â”œâ”€â”€ feature_engineering.py (70+ features ready)
â”‚   â”œâ”€â”€ models.py (Logistic Regression, Random Forest, XGBoost)
â”‚   â”œâ”€â”€ evaluation.py (metrics & visualizations)
â”‚   â””â”€â”€ pnl_calculator.py (strategy & PnL)
â”œâ”€â”€ models/ (will be created)
â”œâ”€â”€ results/ (will be created)
â”œâ”€â”€ main.py (13-step pipeline ready)
â”œâ”€â”€ requirements.txt (ready)
â”œâ”€â”€ README.md (complete documentation)
â””â”€â”€ .gitignore (ready)
```

### Source Code Status
| Module | Status | Key Functions |
|--------|--------|---------------|
| `data_loader.py` | âœ… Ready | load_data(), create_target_column(), train_test_split_timeseries() |
| `feature_engineering.py` | âœ… Ready | 70+ features: technical indicators, candlestick, lag, rolling, temporal |
| `models.py` | âœ… Ready | train_logistic_regression(), train_random_forest(), train_xgboost() |
| `evaluation.py` | âœ… Ready | evaluate_model(), plot_confusion_matrix(), plot_roc_curve() |
| `pnl_calculator.py` | âœ… Ready | generate_signals(), calculate_pnl(), plot_pnl_curve() |
| `main.py` | âœ… Ready | Complete 13-step pipeline |

### Machine Learning Pipeline

**Target Variable**: Binary classification - 1 if next_close > current_close, else 0

**Features (70+)**:
- Technical Indicators: RSI, MACD, Bollinger Bands, SMA, EMA, ATR, Stochastic, ADX
- Candlestick Features: body_size, upper/lower wicks, body/wick ratios
- Lag Features: 1, 2, 3, 5 periods
- Rolling Statistics: 5, 10, 20-period windows (mean, std, min, max)
- Temporal Features: hour, minute, day_of_week
- Price Position: distance from MAs, Bollinger Band position

**Models**:
1. Logistic Regression (baseline)
2. Random Forest (ensemble, n_estimators=100)
3. XGBoost (gradient boosting, expected best performer)

**Data Split**: 70% train / 30% test (chronological, no shuffle for time series)

**Trading Strategy**:
- Buy signal (1): Go long, close at next candle
- Sell signal (0): Go short, close at next candle
- Track trade-by-trade PnL, win rate, drawdown

### Outputs Generated by Pipeline
1. **Processed Data**: `data/processed/train.csv`, `test.csv`, `full_features.csv`
2. **Trained Models**: `models/logistic_regression.pkl`, `random_forest.pkl`, `xgboost.pkl`
3. **Visualizations** (in `results/`):
   - Confusion matrices for all 3 models
   - Feature importance plots (RF & XGBoost)
   - ROC curves with AUC scores
   - PnL curve over time
   - Trade distribution histogram
4. **Final Predictions**: `results/final_predictions.csv` with signals and cumulative PnL

### Next Steps to Run

1. **Install Dependencies** (if not already installed):
   ```powershell
   .\venv\Scripts\activate
   pip install -r requirements.txt
   ```

2. **Run Main Pipeline**:
   ```powershell
   python main.py
   ```
   This executes all 13 steps:
   - Load & preprocess data
   - Create target variable
   - Feature engineering (70+ features)
   - Train-test split (70/30)
   - Feature scaling
   - Train all 3 models
   - Evaluate & compare models
   - Generate predictions & signals
   - Calculate PnL
   - Create visualizations
   - Save all outputs

3. **Explore with Jupyter Notebooks** (optional):
   ```powershell
   jupyter notebook
   ```
   - `01_eda.ipynb`: Data exploration & analysis
   - `02_feature_engineering.ipynb`: Feature testing & correlation
   - `03_model_experiments.ipynb`: Model comparison & tuning

### Expected Runtime
- Data loading & preprocessing: ~30 seconds
- Feature engineering: ~1-2 minutes
- Model training: ~2-5 minutes (depending on hardware)
- Evaluation & PnL: ~30 seconds
- **Total**: 5-8 minutes for complete pipeline

### Key Technical Details
- **Column Mapping**: Data has lowercase columns (timestamp, open, high, low, close) - automatically mapped to Title case in `data_loader.py`
- **Missing Values**: Handled by forward fill method
- **Feature Scaling**: StandardScaler fitted on train set, applied to both train/test
- **Model Selection**: XGBoost typically performs best for time series classification
- **PnL Calculation**: Realistic simulation with entry/exit at next candle

### Dependencies (requirements.txt)
```
pandas==2.0.3
numpy==1.24.3
scikit-learn==1.3.0
xgboost==2.0.0
matplotlib==3.7.1
seaborn==0.12.2
pandas-ta==0.3.14b
joblib==1.3.1
ta==0.11.0
```

## Ready to Execute! ðŸš€
All files are in place. Simply run `python main.py` to start the ML pipeline.
